{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Optimization\n",
    "Gradient based image optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import alexnet_wrapper\n",
    "from utils import norm_image, total_variation_loss\n",
    "import xforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'regularization_scale': 1e-4,\n",
    "    'learning_rate': 0.05,\n",
    "    'total_variation_weight': .5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = 'checkpoints/model.ckpt-115000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_STEPS = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize image as random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_initializer = tf.random_uniform_initializer(\n",
    "    minval=0,\n",
    "    maxval=1,\n",
    ")\n",
    "\n",
    "image_regularizer = tf.contrib.layers.l2_regularizer(\n",
    "    scale=params['regularization_scale']\n",
    ")\n",
    "\n",
    "image_shape = (1, 128, 128, 3)\n",
    "images = tf.get_variable(\n",
    "    \"images\",\n",
    "    image_shape,\n",
    "    initializer=image_initializer,\n",
    "    regularizer=image_regularizer)\n",
    "    \n",
    "print(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do preprocessing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [1 + (i - 5) / 50. for i in range(11)]\n",
    "angles = list(range(-10, 11)) + 5 * [0]\n",
    "print(scales)\n",
    "print(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = xforms.pad(images, pad_amount=12)\n",
    "images = xforms.jitter(images, jitter_amount=8)\n",
    "images = xforms.random_scale(images, scales)\n",
    "images = xforms.random_rotate(images, angles)\n",
    "images = xforms.jitter(images, jitter_amount=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get tensor we want to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_name = 'conv_3' # this is the 4th conv layer of alexnet\n",
    "model_output = alexnet_wrapper(\n",
    "    images,\n",
    "    tensor_name=tensor_name,\n",
    "    train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### specify loss to minimize\n",
    "In this example, I'm going to optimize for high activity for a whole channel (1)\n",
    "\n",
    "(and add regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_channel_activity = tf.reduce_mean(model_output[:, :, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_loss = total_variation_loss(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_reg = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "total_regularization = tv_loss * params['total_variation_weight'] + tf_reg\n",
    "    \n",
    "loss = tf.negative(mean_channel_activity) + total_regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now we need to minimize the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_train = [var for var in tf.trainable_variables() if \"images:0\" == var.name]\n",
    "print(variables_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(params['learning_rate'])\n",
    "train_op = optimizer.minimize(loss, var_list=variables_to_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a Session and restore model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = tf.get_collection_ref(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(\n",
    "    var_list=[v for v in all_variables if \"images\" not in v.name and \"beta\" not in v.name]\n",
    ")\n",
    "saver.restore(sess, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_list = list()\n",
    "tv_list = list()\n",
    "image_list = list()\n",
    "\n",
    "tv_list.append(sess.run(tv_loss))\n",
    "\n",
    "for step in range(NUM_STEPS):\n",
    "    loss_list.append(sess.run(loss))\n",
    "    image_list.append(norm_image(sess.run(images)))\n",
    "    tv_list.append(sess.run(tv_loss))\n",
    "    sess.run(train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(12, 6), ncols=2)\n",
    "axes[0].plot(loss_list, c='k', linewidth=4)\n",
    "axes[1].plot(tv_list, c='k', linewidth=4)\n",
    "\n",
    "# plot formatting\n",
    "for ax in axes:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_xlabel('Steps')\n",
    "    \n",
    "axes[0].set_ylabel('Total Loss')\n",
    "axes[1].set_ylabel('TV Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_list[-1].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"  # for matplotlib 2.1 and above, uses JavaScript\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "l = ax.imshow(np.zeros((128, 128, 3)))\n",
    "\n",
    "def animate(i):\n",
    "    l.set_data(np.squeeze(image_list[i]))\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=NUM_STEPS)\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
