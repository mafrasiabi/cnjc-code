{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20190710_CNJC_variational_autoencoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl-PYQ3w_YWa",
        "colab_type": "text"
      },
      "source": [
        "# CNJC Variational Bayesian Methods\n",
        "\n",
        "This notebook walks through a Variational auto-encoder as introduced by [Kingma & Welling 2013](https://arxiv.org/abs/1312.6114) on the classic MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hCdH_dTZtB2",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBX_zXt8F4eA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Add GPU to Colab notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bb50q2HGHY4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Edit menu -> Notebook Settings -> Hardware accelerator -> select \"GPU\" -> Save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0DUne7uFLOK",
        "colab_type": "text"
      },
      "source": [
        "## imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOHJIOrKHqp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuddxdHIbR2h",
        "colab_type": "code",
        "outputId": "432012ec-1a75-4c48-9af5-175ee4ccac1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim, utils\n",
        "from torchvision import datasets, transforms\n",
        "from torch.nn import functional as F\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import moviepy.editor as mpy\n",
        "from moviepy.video.io.bindings import mplfig_to_npimage\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial\n",
        "device = torch.device(\"cuda\")\n",
        "torch.manual_seed(20190710) # reproducible analysis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3252224/45929032 bytes (7.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6914048/45929032 bytes (15.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b10371072/45929032 bytes (22.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b14024704/45929032 bytes (30.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b17678336/45929032 bytes (38.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b21258240/45929032 bytes (46.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24944640/45929032 bytes (54.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28663808/45929032 bytes (62.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32325632/45929032 bytes (70.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36003840/45929032 bytes (78.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39460864/45929032 bytes (85.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b43188224/45929032 bytes (94.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fdd6b3ce290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMK3bdIVF7AA",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ravFgPvMoPOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dexxJaliMJK",
        "colab_type": "code",
        "outputId": "9945e782-05d2-453a-8bd6-400f69eee0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "batch_size = 128\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "mnist_train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "mnist_test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "# shape is batch_size x 1 x 28 x 28"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8450249.04it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 135841.73it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2222769.65it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 50819.52it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsW4477qKe19",
        "colab_type": "text"
      },
      "source": [
        "# Variational Auto-encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97hxsWbxZUgq",
        "colab_type": "text"
      },
      "source": [
        "## Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF-aSOfoqoZu",
        "colab_type": "text"
      },
      "source": [
        "Implementation based off of PyTorch [basic VAE](https://github.com/pytorch/examples/tree/master/vae)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-kHPXl5GiY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# subclass PyTorch Module for reverse-mode autodifferentiation \n",
        "# for easy backpropogation of loss gradient\n",
        "class VAE(nn.Module):\n",
        "    \n",
        "    def __init__(self, nfeatures,nlatent=20):\n",
        "        super(VAE, self).__init__()\n",
        "        self.nfeatures = nfeatures\n",
        "        self.nhidden = int(nfeatures/5)\n",
        "        \n",
        "        # nn.Linear is a \"dense\" layer of form y = Ax + b\n",
        "        \n",
        "        # Encoder layers\n",
        "        self.hidden_encoder = nn.Linear(nfeatures, self.nhidden)\n",
        "        # mean encoding layer \n",
        "        self.mean_encoder = nn.Linear(self.nhidden, nlatent)\n",
        "        # log variance encoding layer \n",
        "        self.logvar_encoder = nn.Linear(self.nhidden, nlatent)\n",
        "        \n",
        "        # Decoder layers\n",
        "        self.hidden_decoder = nn.Linear(nlatent, int(nfeatures/5))\n",
        "        self.reconstruction_decoder = nn.Linear(self.nhidden, nfeatures)\n",
        "\n",
        "    def encode(self, x):\n",
        "        # we use a ReLu (rectified linear unit) activation function\n",
        "        h1 = F.relu(self.hidden_encoder(x))\n",
        "        return self.mean_encoder(h1), self.logvar_encoder(h1)\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        \"\"\"Reparameterize out stochastic node so the gradient can propogate \n",
        "           deterministically.\"\"\"\n",
        "\n",
        "        if self.training:\n",
        "            standard_deviation = torch.exp(0.5*logvar)\n",
        "            # sample from unit gaussian with same shape as standard_deviation\n",
        "            epsilon = torch.randn_like(standard_deviation)\n",
        "            # TODO: write this line. Stuck? see answers at bottom of notebook\n",
        "            return NotImplementedError()\n",
        "        else:\n",
        "            return mean\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.hidden_decoder(z))\n",
        "        # use sigmoid to bound output to (0,1)\n",
        "        return F.sigmoid(self.reconstruction_decoder(h3))\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"A special method in PyTorch modules that is called by __call__\"\n",
        "        \n",
        "        # flatten batch x height x width into batch x nFeatures, then encode\n",
        "        mean, logvar = self.encode(x.view(-1, self.nfeatures))\n",
        "        # sample an embedding, z\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "        # return the (sampled) reconstruction, mean, and log variance\n",
        "        return self.decode(z), mean, logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWpKubfCKnHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(recon_x, x, mu, logvar, nfeatures):\n",
        "    \"Reconstruction + KL divergence losses summed over all elements and batch.\"\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, nfeatures), size_average=False)\n",
        "\n",
        "    # we want KLD = - 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    # where sigma is standard deviation and mu is mean\n",
        "    # (interested? check out Appendix B of https://arxiv.org/abs/1312.6114)\n",
        "    # In pytorch, x^2 is written as x.pow(2), e^x is written as x.exp(),\n",
        "    # and sum_{i=1}^n (x_i + y_i) for x,y of length n\n",
        "    # can be written as torch.sum(x+y)\n",
        "    # TODO: write this line. Stuck? see answers at bottom of notebook\n",
        "    KLD = NotImplementedError()\n",
        "\n",
        "    return BCE + KLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1sjVOJsZbze",
        "colab_type": "text"
      },
      "source": [
        "## train & test functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKTRHpNgSE1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch, model, optimizer, train_loader, log_interval=10):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        data = data[0].to(device)  # we ignore any labels & transfer to GPU\n",
        "        nfeatures = data[0].numel()\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar, nfeatures)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / len(data)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))\n",
        "\n",
        "\n",
        "def test(epoch, model, test_loader,folder=\"results\"):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader):\n",
        "            data = data[0].to(device)\n",
        "            nfeatures = data[0].numel()\n",
        "            n = min(data.size(0), 15)\n",
        "            if len(data.shape)==3:\n",
        "                  # zebrafish\n",
        "                _, H, W = data.shape\n",
        "                dat = data[:n,None]\n",
        "            elif len(data.shape)==4:\n",
        "                  # MNIST\n",
        "                _, _, H, W = data.shape\n",
        "                dat = data[:n]\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar, nfeatures).item()\n",
        "            if i == 0:              \n",
        "                comparison = torch.cat([dat,\n",
        "                                   recon_batch.view(-1, 1, H, W)[:n]])\n",
        "                torchvision.utils.save_image(comparison.cpu(),\n",
        "                         folder+'/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGhgMsOTiq07",
        "colab_type": "text"
      },
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFBtjP0liuB9",
        "colab_type": "code",
        "outputId": "780bd21e-e552-4fe0-a66c-11990158c26d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# run cell to reset model\n",
        "nfeatures = 28**2\n",
        "# we use a latent space of dimension 2 as to get an easy-to-visualize manifold\n",
        "# (see mnist/sample_*.png while running next cell)\n",
        "nlatent = 2\n",
        "mnist_model = VAE(nfeatures,nlatent=nlatent).to(device)\n",
        "mnist_optimizer = optim.Adam(mnist_model.parameters(), lr=1e-3)\n",
        "!rm mnist/*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'mnist/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMU_wru9i879",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will take two minutes to run.\n",
        "# As it does, check out the mnist folder!\n",
        "# each epoch, reconstruction examples are saved (original on top) \n",
        "# select files on right, then refresh, and double click image\n",
        "# click bottom right corner of image to resize\n",
        "\n",
        "nepochs = 2\n",
        "H, W = (28,28)\n",
        "\n",
        "# make grid of z1 x z2 where z1,z2 \\elem (-3.5,-2.5, ..., 3.5)\n",
        "nrow = 25\n",
        "latents = torch.zeros(nrow,nrow,nlatent)\n",
        "z1_tick = np.linspace(-3.5,3.5,nrow)\n",
        "z2_tick = np.linspace(-3.5,3.5,nrow)\n",
        "for i, z1 in enumerate(z1_tick):\n",
        "    for j, z2 in enumerate(z2_tick):\n",
        "        latents[i,j,[0,1]] = torch.tensor([z1,z2])\n",
        "latents = latents.to(device)\n",
        "\n",
        "for epoch in range(1, nepochs + 1):\n",
        "    train(epoch, mnist_model, mnist_optimizer, mnist_train_loader)\n",
        "    test(epoch, mnist_model, mnist_test_loader,folder='mnist')\n",
        "    with torch.no_grad():\n",
        "        latent_space = mnist_model.decode(latents.view(-1,nlatent)).cpu()\n",
        "        torchvision.utils.save_image(latent_space.view(-1, 1, H, W),\n",
        "                   'mnist/sample_' + str(epoch) + '.png',nrow=nrow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_JZP0VCU8nB",
        "colab_type": "text"
      },
      "source": [
        "# Stuck? Here's the answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1M1rmiVVd78",
        "colab_type": "text"
      },
      "source": [
        "## reparameterize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zbjv-60VBaV",
        "colab_type": "text"
      },
      "source": [
        "`return epsilon * standard_deviation + mean`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyesxUUoVjvZ",
        "colab_type": "text"
      },
      "source": [
        "## loss_function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUsqw45BVl6T",
        "colab_type": "text"
      },
      "source": [
        "`KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())`"
      ]
    }
  ]
}